= Package Death Row =

We start by creating a pair of temporary directories to be used in
this test.

    >>> import tempfile
    >>> pool_path = tempfile.mkdtemp('-pool')
    >>> temp_path = tempfile.mkdtemp('-pool-tmp')

We will work within the Ubuntu distribution context only.

    >>> from lp.registry.interfaces.distribution import (
    ...      IDistributionSet)
    >>> ubuntu = getUtility(IDistributionSet).getByName('ubuntu')

The no-operation use case, reflects the sampledata status.

    >>> from lp.services.log.logger import FakeLogger
    >>> from lp.archivepublisher.deathrow import DeathRow
    >>> from lp.archivepublisher.diskpool import DiskPool

    >>> disk_pool = DiskPool(pool_path, temp_path, FakeLogger())
    >>> death_row = DeathRow(ubuntu.main_archive, disk_pool, FakeLogger())
    >>> death_row.reap(dry_run=True)
    DEBUG 0 Sources
    DEBUG 0 Binaries
    INFO Removing 0 files marked for reaping
    INFO Total bytes freed: 0
    DEBUG Marking 0 condemned packages as removed.


== Removal unreferenced packages ==

Setup `SoyuzTestPublisher` for creating publications for Ubuntu/hoary.

    >>> from lp.soyuz.tests.test_publishing import (
    ...     SoyuzTestPublisher)
    >>> from lp.registry.interfaces.pocket import PackagePublishingPocket
    >>> from lp.soyuz.enums import (
    ...     PackagePublishingStatus)

    >>> hoary = ubuntu.getSeries('hoary')

    >>> test_publisher = SoyuzTestPublisher()
    >>> test_publisher.addFakeChroots(hoary)
    >>> unused = test_publisher.setUpDefaultDistroSeries(hoary)

Build a 'past' and a 'future' timestamps to be used as
'scheduleddeletiondate'.

    >>> import datetime
    >>> import pytz

    >>> UTC = pytz.timezone('UTC')
    >>> this_year = datetime.datetime.now().year

    >>> past_date = datetime.datetime(
    ...     year=this_year - 2, month=1, day=1, tzinfo=UTC)
    >>> future_date = datetime.datetime(
    ...     year=this_year + 2, month=1, day=1, tzinfo=UTC)

Create source publications in various statuses that are all ready to
be removed.

    >>> deleted_source = test_publisher.getPubSource(
    ...     sourcename="deleted",
    ...     status=PackagePublishingStatus.DELETED,
    ...     filecontent='X',
    ...     scheduleddeletiondate=past_date)

    >>> superseded_source = test_publisher.getPubSource(
    ...     sourcename="superseded",
    ...     status=PackagePublishingStatus.SUPERSEDED,
    ...     filecontent='X',
    ...     scheduleddeletiondate=past_date)

    >>> obsolete_source = test_publisher.getPubSource(
    ...     sourcename="obsolete",
    ...     status=PackagePublishingStatus.OBSOLETE,
    ...     filecontent='X',
    ...     scheduleddeletiondate=past_date)

Create a chain of dependent source publications:

 * 'removed_source': ready to be removed;
 * 'postponed_source': still in quarantine time;
 * 'published_source': still published.

    >>> removed_source = test_publisher.getPubSource(
    ...     sourcename="stuck",
    ...     status=PackagePublishingStatus.SUPERSEDED,
    ...     filecontent='A',
    ...     scheduleddeletiondate=past_date)

    >>> postponed_source = test_publisher.getPubSource(
    ...     sourcename="stuck", version="667",
    ...     status=PackagePublishingStatus.SUPERSEDED,
    ...     filecontent='B',
    ...     scheduleddeletiondate=future_date)

    >>> published_source = test_publisher.getPubSource(
    ...     sourcename="stuck", version="668",
    ...     filecontent='C',
    ...     status=PackagePublishingStatus.PUBLISHED)

They all share a source file.

    >>> shared_file = test_publisher.addMockFile(
    ...     'shared_1.0.tar.gz', filecontent='Y')
    >>> discard = removed_source.sourcepackagerelease.addFile(shared_file)
    >>> discard = postponed_source.sourcepackagerelease.addFile(shared_file)
    >>> discard = published_source.sourcepackagerelease.addFile(shared_file)

Create binary publications in various statuses that are all ready to
be removed.

    >>> deleted_base_source = test_publisher.getPubSource(
    ...     sourcename='deleted-ignored', architecturehintlist='i386')
    >>> [deleted_binary] = test_publisher.getPubBinaries(
    ...     binaryname="deleted-bin",
    ...     pub_source=deleted_base_source,
    ...     status=PackagePublishingStatus.DELETED,
    ...     filecontent='Z',
    ...     scheduleddeletiondate = past_date)

    >>> superseded_base_source = test_publisher.getPubSource(
    ...     sourcename='superseded-ignored', architecturehintlist='i386')
    >>> [superseded_binary] = test_publisher.getPubBinaries(
    ...     binaryname="superseded-bin",
    ...     pub_source=superseded_base_source,
    ...     status=PackagePublishingStatus.SUPERSEDED,
    ...     filecontent='Z',
    ...     scheduleddeletiondate = past_date)

    >>> obsolete_base_source = test_publisher.getPubSource(
    ...     sourcename='obsolete-ignored', architecturehintlist='i386')
    >>> [obsolete_binary] = test_publisher.getPubBinaries(
    ...     binaryname="obsolete-bin",
    ...     pub_source=obsolete_base_source,
    ...     status=PackagePublishingStatus.OBSOLETE,
    ...     filecontent='Z',
    ...     scheduleddeletiondate = past_date)

Dependent binary publications.

    >>> removed_base_source = test_publisher.getPubSource(
    ...     sourcename='removed-ignored', architecturehintlist='i386',
    ...     pocket=PackagePublishingPocket.SECURITY)
    >>> [removed_binary] = test_publisher.getPubBinaries(
    ...     binaryname="stuck-bin",
    ...     pub_source=removed_base_source,
    ...     status=PackagePublishingStatus.SUPERSEDED,
    ...     filecontent='Z',
    ...     scheduleddeletiondate = past_date)

    >>> [postponed_binary] =  removed_binary.copyTo(
    ...     hoary, PackagePublishingPocket.PROPOSED, ubuntu.main_archive)
    >>> postponed_binary.status = (
    ...     PackagePublishingStatus.SUPERSEDED)
    >>> postponed_binary.scheduleddeletiondate = future_date

    >>> [published_binary] =  removed_binary.copyTo(
    ...     hoary, PackagePublishingPocket.UPDATES, ubuntu.main_archive)
    >>> published_binary.status = (
    ...     PackagePublishingStatus.PUBLISHED)

Store the 'removable' context in the database as a checkpoint, so it
can be reused later.

    >>> transaction.commit()

Group the test publications according to their purpose:

    >>> removed_records = (
    ...     deleted_source,
    ...     superseded_source,
    ...     obsolete_source,
    ...     deleted_binary,
    ...     superseded_binary,
    ...     obsolete_binary,
    ...     )

    >>> dependent_records = (
    ...    removed_source,
    ...    postponed_source,
    ...    published_source,
    ...    removed_binary,
    ...    postponed_binary,
    ...    published_binary,
    ...    )

    >>> all_test_publications = removed_records + dependent_records

Publish files on disk and build a list of all created file paths

    >>> from lp.services.log.logger import BufferLogger
    >>> quiet_disk_pool = DiskPool(pool_path, temp_path, BufferLogger())

    >>> unique_file_paths = set()

    >>> for pub in all_test_publications:
    ...     for pub_file in pub.files:
    ...         for pub_file in pub.files:
    ...             file_path = quiet_disk_pool.pathFor(
    ...                 pub_file.componentname.encode('utf-8'),
    ...                 pub_file.sourcepackagename.encode('utf8'),
    ...                 pub_file.libraryfilealiasfilename.encode('utf-8')
    ...              )
    ...             unique_file_paths.add(file_path)
    ...             pub_file.publish(quiet_disk_pool, BufferLogger())

    >>> all_test_file_paths = sorted(unique_file_paths)

Create a helper function to check if the publication files exist in
the temporary repository.

    >>> import os
    >>> def check_pool_files():
    ...     for file_path in all_test_file_paths:
    ...         if os.path.exists(file_path):
    ...             print '%s: OK' % os.path.basename(file_path)
    ...         else:
    ...             print '%s: REMOVED' % os.path.basename(file_path)

    >>> check_pool_files()
    deleted-bin_666_i386.deb:    OK
    deleted_666.dsc:             OK
    obsolete-bin_666_i386.deb:   OK
    obsolete_666.dsc:            OK
    stuck-bin_666_i386.deb:      OK
    shared_1.0.tar.gz:           OK
    stuck_666.dsc:               OK
    stuck_667.dsc:               OK
    stuck_668.dsc:               OK
    superseded-bin_666_i386.deb: OK
    superseded_666.dsc:          OK

Run DeathRow against the current 'removable' context.

    >>> disk_pool = DiskPool(pool_path, temp_path, FakeLogger())
    >>> death_row = DeathRow(ubuntu.main_archive, disk_pool, FakeLogger())
    >>> death_row.reap()
    DEBUG 4 Sources
    DEBUG 3 Binaries
    ...
    DEBUG Checking superseded_666.dsc (02129bb861061d1a052c592e2dc6b383)
    DEBUG Checking obsolete_666.dsc (02129bb861061d1a052c592e2dc6b383)
    ...
    INFO Removing 7 files marked for reaping
    DEBUG Removing superseded/superseded_666.dsc from main
    DEBUG Removing superseded-ignored/superseded-bin_666_i386.deb from main
    DEBUG Removing stuck/stuck_666.dsc from main
    DEBUG Removing obsolete/obsolete_666.dsc from main
    DEBUG Removing obsolete-ignored/obsolete-bin_666_i386.deb from main
    DEBUG Removing deleted/deleted_666.dsc from main
    DEBUG Removing deleted-ignored/deleted-bin_666_i386.deb from main
    INFO Total bytes freed: 7
    DEBUG Marking 7 condemned packages as removed.

A few details to pay attention to in the log output:

 * All files were checked despite having the same content. In
   normal circunstances this can be achieved by having the same tarball
   used with different names for two distinct sourcepackages
   (openoffice and openoffice-l10n is an example);

 * The source file shared across publications ('shared_1.0.tar.gz')
   wasn't removed as it is still related to a 'live' and a
   'future-deletion' publications.

 * Dependent binaries are only possible via publication copies and are
   only removed 'atomically', i.e. since there is a 'live' publication
   in the UPDATES pocket they are not even considered for removal. See
   more about this specific use-case below.

 * The files created in the temporary repository have only 1 byte,
   thus removing 7 files results in the right sum of bytes freed (7
   bytes).

The removed publications were marked as 'removed' and their publishing
status was preserved in the database.

    >>> def check_removed(pub):
    ...     properly_removed = pub.dateremoved is not None
    ...     print pub.displayname, pub.status.name, properly_removed

    >>> for pub in removed_records:
    ...     check_removed(pub)
    deleted 666 in hoary             DELETED    True
    superseded 666 in hoary          SUPERSEDED True
    obsolete 666 in hoary            OBSOLETE   True
    deleted-bin 666 in hoary i386    DELETED    True
    superseded-bin 666 in hoary i386 SUPERSEDED True
    obsolete-bin 666 in hoary i386   OBSOLETE   True

The dependent publications were processed as expected; only the one
with 'scheduleddeletiondate' set to the past was removed, the one with
future timestamp and the published one were kept. No binary
publications was removed (see more below).

    >>> for pub in dependent_records:
    ...     check_removed(pub)
    stuck 666 in hoary          SUPERSEDED True
    stuck 667 in hoary          SUPERSEDED False
    stuck 668 in hoary          PUBLISHED  False
    stuck-bin 666 in hoary i386 SUPERSEDED False
    stuck-bin 666 in hoary i386 SUPERSEDED False
    stuck-bin 666 in hoary i386 PUBLISHED  False

The repository was also left in the expected state.

    >>> check_pool_files()
    deleted-bin_666_i386.deb:    REMOVED
    deleted_666.dsc:             REMOVED
    obsolete-bin_666_i386.deb:   REMOVED
    obsolete_666.dsc:            REMOVED
    stuck-bin_666_i386.deb:      OK
    shared_1.0.tar.gz:           OK
    stuck_666.dsc:               REMOVED
    stuck_667.dsc:               OK
    stuck_668.dsc:               OK
    superseded-bin_666_i386.deb: REMOVED
    superseded_666.dsc:          REMOVED

As mentioned above, binary publications are only removed atomically
since they are related to only a single file (files can't be
shared). In order to trigger the consideration of these specific
publications we have to remove any 'live' publications.

    >>> published_binary.status = (
    ...    PackagePublishingStatus.SUPERSEDED)
    >>> published_binary.scheduleddeletiondate = past_date

Now DeathRow considers 'stuck-bin' publications.

    >>> disk_pool = DiskPool(pool_path, temp_path, FakeLogger())
    >>> death_row = DeathRow(ubuntu.main_archive, disk_pool, FakeLogger())
    >>> death_row.reap()
    DEBUG 0 Sources
    DEBUG 2 Binaries
    DEBUG Checking stuck-bin_666_i386.deb (21c2e59531c8710156d34a3c30ac81d5)
    DEBUG Cannot remove.
    DEBUG Checking stuck-bin_666_i386.deb (21c2e59531c8710156d34a3c30ac81d5)
    DEBUG Already verified.
    INFO Removing 0 files marked for reaping
    INFO Total bytes freed: 0
    DEBUG Marking 0 condemned packages as removed.

After being considered for removal, DeathRow realized that this binary
could not be removed because there is still a publishing record
imposing quarantine on it. Once the quarantine is lifted, by setting a
'past' scheduleddeletiondate, the binary file finally gets removed
from the repository.

    >>> postponed_binary.scheduleddeletiondate = past_date

That done, the publication and its files are free to be removed in a
single pass.

    >>> disk_pool = DiskPool(pool_path, temp_path, FakeLogger())
    >>> death_row = DeathRow(ubuntu.main_archive, disk_pool, FakeLogger())
    >>> death_row.reap()
    DEBUG 0 Sources
    DEBUG 3 Binaries
    DEBUG Checking stuck-bin_666_i386.deb (21c2e59531c8710156d34a3c30ac81d5)
    DEBUG Checking stuck-bin_666_i386.deb (21c2e59531c8710156d34a3c30ac81d5)
    DEBUG Already verified.
    DEBUG Checking stuck-bin_666_i386.deb (21c2e59531c8710156d34a3c30ac81d5)
    DEBUG Already verified.
    INFO Removing 1 files marked for reaping
    DEBUG Removing removed-ignored/stuck-bin_666_i386.deb from main
    INFO Total bytes freed: 1
    DEBUG Marking 3 condemned packages as removed.

The file was removed from the repository.

    >>> dependent_binaries = (
    ...     published_binary,
    ...     postponed_binary,
    ...     removed_binary,
    ... )

    >>> check_pool_files()
    deleted-bin_666_i386.deb:    REMOVED
    deleted_666.dsc:             REMOVED
    obsolete-bin_666_i386.deb:   REMOVED
    obsolete_666.dsc:            REMOVED
    stuck-bin_666_i386.deb:      REMOVED
    shared_1.0.tar.gz:           OK
    stuck_666.dsc:               REMOVED
    stuck_667.dsc:               OK
    stuck_668.dsc:               OK
    superseded-bin_666_i386.deb: REMOVED
    superseded_666.dsc:          REMOVED

And the related publishing records are marked as removed in the
database.

    >>> for pub in dependent_binaries:
    ...     check_removed(pub)
    stuck-bin 666 in hoary i386 SUPERSEDED True
    stuck-bin 666 in hoary i386 SUPERSEDED True
    stuck-bin 666 in hoary i386 SUPERSEDED True

Remove temporary diretories used for tests.

    >>> import shutil
    >>> shutil.rmtree(pool_path)
    >>> shutil.rmtree(temp_path)
